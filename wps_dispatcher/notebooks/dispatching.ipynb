{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIT Dispatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona.transform\n",
    "import time\n",
    "import asyncio, aiohttp, xmltodict\n",
    "import string\n",
    "\n",
    "if not hasattr(asyncio, 'create_task'):\n",
    "    asyncio.create_task = asyncio.ensure_future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polygons can be read directly from the zipped shapefile supplied. (However, an optimisation would be to store the vector data in the target projection.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_polygons(max_index=None, max_length=None):\n",
    "    \"\"\"Produce indexed WGS84 polygons from shapefile\"\"\"\n",
    "    source = \"zip://Queensland_dominant_wetland_areas_22042020.zip\"\n",
    "    with fiona.open(source) as collection:\n",
    "        #collection.ignore_fields = list(collection.schema['properties']) # read fewer columns\n",
    "        for i, record in enumerate(collection):\n",
    "            if max_length and record['properties']['Shape_Leng'] > max_length:\n",
    "                continue\n",
    "            # Note, reprojection is very slow, and could instead be prepared prior to runtime. \n",
    "            geom = fiona.transform.transform_geom(collection.crs, 'EPSG:4326', record['geometry'])\n",
    "            geom['coordinates'] = [[[lon, lat] for (lat, lon) in ring] for ring in geom['coordinates']]\n",
    "            yield i, geom\n",
    "            if max_index and i >= max_index:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polygons must be encoded into WPS *execute* requests, together with a time interval. For WIT, it is unimportant whether all time is processed in a single interval, or divided into multiple successive increments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_template = \"\"\"\n",
    "<wps:Execute version=\"1.0.0\" service=\"WPS\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://www.opengis.net/wps/1.0.0\" xmlns:wfs=\"http://www.opengis.net/wfs\" xmlns:wps=\"http://www.opengis.net/wps/1.0.0\" xmlns:ows=\"http://www.opengis.net/ows/1.1\" xmlns:gml=\"http://www.opengis.net/gml\" xmlns:ogc=\"http://www.opengis.net/ogc\" xmlns:wcs=\"http://www.opengis.net/wcs/1.1.1\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xsi:schemaLocation=\"http://www.opengis.net/wps/1.0.0 http://schemas.opengis.net/wps/1.0.0/wpsAll.xsd\">\n",
    "    <ows:Identifier>WIT</ows:Identifier>\n",
    "    <wps:DataInputs>\n",
    "    <wps:Input>\n",
    "        <ows:Identifier>geometry</ows:Identifier>\n",
    "        <wps:Data>\n",
    "        <wps:ComplexData>{\"type\":\"FeatureCollection\",\"features\":[{\"type\":\"Feature\",\"geometry\":%s}]}</wps:ComplexData>\n",
    "        </wps:Data>\n",
    "    </wps:Input>\n",
    "    <wps:Input>\n",
    "        <ows:Identifier>start</ows:Identifier>\n",
    "        <wps:Data>\n",
    "        <wps:ComplexData>{\"type\":\"object\",\"properties\":{\"timestamp\":{\"type\":\"string\",\"format\":\"date-time\",\"date-time\":\"2010-01-01T00:00\"}}}</wps:ComplexData>\n",
    "        </wps:Data>\n",
    "    </wps:Input>\n",
    "    <wps:Input>\n",
    "        <ows:Identifier>end</ows:Identifier>\n",
    "        <wps:Data>\n",
    "        <wps:ComplexData>{\"type\":\"object\",\"properties\":{\"timestamp\":{\"type\":\"string\",\"format\":\"date-time\",\"date-time\":\"2011-01-01T00:00\"}}}</wps:ComplexData>\n",
    "        </wps:Data>\n",
    "    </wps:Input>\n",
    "    </wps:DataInputs>\n",
    "    <wps:ResponseForm>\n",
    "    <wps:ResponseDocument storeExecuteResponse=\"true\" status=\"true\"/>\n",
    "    </wps:ResponseForm>\n",
    "</wps:Execute>\n",
    "\"\"\"\n",
    "def request_doc(geom):\n",
    "    return request_template % str(geom).replace(\"'\", '\"').replace(' ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing, we just want a few individual requests for the WPS, and to exclude any large polygons. There is also a simpler request example that only targets a pixel drill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_requests = ((i, request_doc(poly)) for i, poly in generate_polygons(max_index=10, max_length=2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to poll the WPS for requests to be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wps_url = 'https://ows.dev.dea.ga.gov.au/wps/?service=WPS&request=Execute'\n",
    "wps_headers = {'Content-Type': 'text/xml;charset=UTF-8', 'cache-control': 'max-age=0'}\n",
    "polling_interval = 2.0 # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def request(session, log, index, request_doc):\n",
    "    \"Execute a single request, and process through to completion\"\n",
    "    try:\n",
    "        resp = await session.post(wps_url, data=request_doc, headers=wps_headers)\n",
    "        assert resp.status == 200\n",
    "        info = xmltodict.parse(await resp.text())\n",
    "        url = info['wps:ExecuteResponse']['@statusLocation']\n",
    "        log[index] = [url]\n",
    "        assert 'wps:ProcessAccepted' in info['wps:ExecuteResponse']['wps:Status'] \n",
    "        while {'wps:ProcessAccepted', 'wps:ProcessStarted'} & set(info['wps:ExecuteResponse']['wps:Status']):\n",
    "            await asyncio.sleep(polling_interval)\n",
    "            resp = await session.get(url)\n",
    "            assert resp.status == 200\n",
    "            info = xmltodict.parse(await resp.text())\n",
    "        assert 'wps:ProcessSucceeded' in info['wps:ExecuteResponse']['wps:Status']\n",
    "        log[index].append('Succeeded')\n",
    "        result = info['wps:ExecuteResponse']['wps:ProcessOutputs']['wps:Output']['wps:Data']\\\n",
    "                     ['wps:LiteralData']['#text']\n",
    "        log[index].append(result)\n",
    "        return info['wps:ExecuteResponse']['wps:ProcessOutputs']\n",
    "    except:\n",
    "        log[index].append('Failed')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def distribute(task_generator, func, max_concurrency):\n",
    "    \"\"\"Apply func to each task, while still limiting how many are loaded in memory\"\"\"\n",
    "    \n",
    "    sem = asyncio.Semaphore(max_concurrency)\n",
    "    \n",
    "    async def wrapper(args):\n",
    "        try:\n",
    "            await func(*args)\n",
    "        finally:\n",
    "            sem.release()\n",
    "    \n",
    "    for args in task_generator:\n",
    "        await sem.acquire()\n",
    "        asyncio.create_task(wrapper(args))\n",
    "        \n",
    "    # wait for completion\n",
    "    for i in range(max_concurrency):\n",
    "        await sem.acquire()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def monitor(log, task):\n",
    "    \n",
    "    process = asyncio.create_task(task)\n",
    "    \n",
    "    while not process.done():\n",
    "        await asyncio.sleep(0.2)\n",
    "        \n",
    "        started = len(log)\n",
    "        success = sum(1 for i in log if 'Succeeded' in log[i])\n",
    "        failure = sum(1 for i in log if 'Failed' in log[i])\n",
    "        unfinished = started - (success + failure)\n",
    "        \n",
    "        print(f\"{unfinished} running, {success} completed, {failure} failed.\", end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 running, 10 completed, 0 failed.\r"
     ]
    }
   ],
   "source": [
    "log = {}\n",
    "\n",
    "async with aiohttp.ClientSession() as session:\n",
    "    \n",
    "    await monitor(log, distribute(example_requests, lambda *args: request(session, log, *args), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ['https://s3.ap-southeast-2.amazonaws.com/dea-dev-wps-results/9ddb8698-dd60-11eb-aefd-fa59ad39ec44.xml',\n",
       "  'Succeeded',\n",
       "  's3://dea-dev-wps-results/wit/9ddb8698-dd60-11eb-aefd-fa59ad39ec44/9ddb8698-dd60-11eb-aefd-fa59ad39ec44.snappy.parquet'],\n",
       " 0: ['https://s3.ap-southeast-2.amazonaws.com/dea-dev-wps-results/9e734c62-dd60-11eb-aefd-fa59ad39ec44.xml',\n",
       "  'Succeeded',\n",
       "  's3://dea-dev-wps-results/wit/9e734c62-dd60-11eb-aefd-fa59ad39ec44/9e734c62-dd60-11eb-aefd-fa59ad39ec44.snappy.parquet'],\n",
       " 2: ['https://s3.ap-southeast-2.amazonaws.com/dea-dev-wps-results/2c157964-dd61-11eb-aefd-fa59ad39ec44.xml',\n",
       "  'Succeeded',\n",
       "  's3://dea-dev-wps-results/wit/2c157964-dd61-11eb-aefd-fa59ad39ec44/2c157964-dd61-11eb-aefd-fa59ad39ec44.snappy.parquet'],\n",
       " 3: ['https://s3.ap-southeast-2.amazonaws.com/dea-dev-wps-results/2cbb9e02-dd61-11eb-aefd-fa59ad39ec44.xml',\n",
       "  'Succeeded',\n",
       "  's3://dea-dev-wps-results/wit/2cbb9e02-dd61-11eb-aefd-fa59ad39ec44/2cbb9e02-dd61-11eb-aefd-fa59ad39ec44.snappy.parquet'],\n",
       " 5: ['https://s3.ap-southeast-2.amazonaws.com/dea-dev-wps-results/8f226e86-dd61-11eb-aefd-fa59ad39ec44.xml',\n",
       "  'Succeeded',\n",
       "  's3://dea-dev-wps-results/wit/8f226e86-dd61-11eb-aefd-fa59ad39ec44/8f226e86-dd61-11eb-aefd-fa59ad39ec44.snappy.parquet'],\n",
       " 6: ['https://s3.ap-southeast-2.amazonaws.com/dea-dev-wps-results/9d5fb576-dd61-11eb-aefd-fa59ad39ec44.xml',\n",
       "  'Succeeded',\n",
       "  's3://dea-dev-wps-results/wit/9d5fb576-dd61-11eb-aefd-fa59ad39ec44/9d5fb576-dd61-11eb-aefd-fa59ad39ec44.snappy.parquet'],\n",
       " 7: ['https://s3.ap-southeast-2.amazonaws.com/dea-dev-wps-results/f223e014-dd61-11eb-aefd-fa59ad39ec44.xml',\n",
       "  'Succeeded',\n",
       "  's3://dea-dev-wps-results/wit/f223e014-dd61-11eb-aefd-fa59ad39ec44/f223e014-dd61-11eb-aefd-fa59ad39ec44.snappy.parquet'],\n",
       " 8: ['https://s3.ap-southeast-2.amazonaws.com/dea-dev-wps-results/0674171e-dd62-11eb-aefd-fa59ad39ec44.xml',\n",
       "  'Succeeded',\n",
       "  's3://dea-dev-wps-results/wit/0674171e-dd62-11eb-aefd-fa59ad39ec44/0674171e-dd62-11eb-aefd-fa59ad39ec44.snappy.parquet'],\n",
       " 9: ['https://s3.ap-southeast-2.amazonaws.com/dea-dev-wps-results/566145e4-dd62-11eb-aefd-fa59ad39ec44.xml',\n",
       "  'Succeeded',\n",
       "  's3://dea-dev-wps-results/wit/566145e4-dd62-11eb-aefd-fa59ad39ec44/566145e4-dd62-11eb-aefd-fa59ad39ec44.snappy.parquet'],\n",
       " 10: ['https://s3.ap-southeast-2.amazonaws.com/dea-dev-wps-results/b0f0a5e0-dd62-11eb-aefd-fa59ad39ec44.xml',\n",
       "  'Succeeded',\n",
       "  's3://dea-dev-wps-results/wit/b0f0a5e0-dd62-11eb-aefd-fa59ad39ec44/b0f0a5e0-dd62-11eb-aefd-fa59ad39ec44.snappy.parquet']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
